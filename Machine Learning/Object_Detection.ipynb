{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xeo_C2faIjHr"
      },
      "source": [
        "## Initializing File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x1HctLvlDn11"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bgP9npDbDyJW"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'SSD_MOBNET' \n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BSV2HSuJIYv_"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Kinder', 'Workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Kinder','Scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Kinder','Models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Kinder', 'Workspace','Annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Kinder', 'Workspace','Images'),\n",
        "    'MODEL_PATH': os.path.join('Kinder', 'Workspace','Models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Kinder', 'Workspace','Pretrained'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Kinder', 'Workspace','Models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Kinder', 'Workspace','Models',CUSTOM_MODEL_NAME, 'Export'), \n",
        "    'TFJS_PATH':os.path.join('Kinder', 'Workspace','Models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Kinder', 'Workspace','Models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Kinder','Protoc')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qgFSdW8QIbLB"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Kinder', 'Workspace', 'Models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jskV-1jcIejs"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrtRZaA_JM2z"
      },
      "source": [
        "## Colab Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffLUhBqnJJD9",
        "outputId": "27a4c721-c59e-4610-d83a-f38f97f9e502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Bb_d61BCMLoQ"
      },
      "outputs": [],
      "source": [
        "!sudo cp -r /content/drive/My\\ Drive/Images Kinder/Workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVJL5OtqOQYv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQMIAKWMOX5e"
      },
      "source": [
        "## Pretrained Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "94YqjqM5OaQI"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n5TIPa8zOwif",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa074fc-8c20-4044-a1d8-3b56d9fd91a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/Kinder/Models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.39.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.30)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.9.2)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.26.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.17.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.96)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Collecting tensorflow~=2.9.0\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Kinder/Models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlQF2oAFQV7V",
        "outputId": "ab571d41-0833-4498-bf3a-14537c9135ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-06-07 05:11:45.531167: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0607 05:11:45.743620 139665927477120 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.31s\n",
            "I0607 05:11:46.095745 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.31s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.56s\n",
            "I0607 05:11:46.657337 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.56s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.28s\n",
            "I0607 05:11:46.940777 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.28s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n",
            "I0607 05:11:47.162619 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.22s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.67s\n",
            "I0607 05:11:48.830490 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.67s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0607 05:11:48.831477 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0607 05:11:48.852654 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0607 05:11:48.865908 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0607 05:11:48.879622 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "I0607 05:11:48.970323 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "I0607 05:11:49.055571 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.08s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "I0607 05:11:49.147606 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "I0607 05:11:49.240396 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "I0607 05:11:49.335305 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0607 05:11:49.364045 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0607 05:11:49.540611 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0607 05:11:49.540776 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0607 05:11:49.540858 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0607 05:11:49.542924 139665927477120 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0607 05:11:49.558250 139665927477120 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0607 05:11:49.558366 139665927477120 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0607 05:11:49.611677 139665927477120 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0607 05:11:49.611809 139665927477120 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0607 05:11:49.749213 139665927477120 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0607 05:11:49.749379 139665927477120 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0607 05:11:49.884525 139665927477120 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0607 05:11:49.884696 139665927477120 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0607 05:11:50.088636 139665927477120 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0607 05:11:50.088805 139665927477120 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0607 05:11:50.302575 139665927477120 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0607 05:11:50.302754 139665927477120 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0607 05:11:50.796082 139665927477120 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0607 05:11:50.796307 139665927477120 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0607 05:11:50.902270 139665927477120 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0607 05:11:50.944818 139665927477120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0607 05:11:51.046221 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0607 05:11:51.046437 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0607 05:11:51.046576 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0607 05:11:51.049177 139665927477120 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0607 05:11:51.074535 139665927477120 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0607 05:11:51.074681 139665927477120 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0607 05:11:51.498402 139665927477120 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0607 05:11:51.498659 139665927477120 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0607 05:11:51.876997 139665927477120 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0607 05:11:51.877224 139665927477120 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0607 05:11:52.233293 139665927477120 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0607 05:11:52.233536 139665927477120 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0607 05:11:52.677341 139665927477120 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0607 05:11:52.677579 139665927477120 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0607 05:11:53.161668 139665927477120 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0607 05:11:53.161884 139665927477120 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0607 05:11:53.810976 139665927477120 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0607 05:11:53.818659 139665927477120 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0607 05:11:54.085738 139665927477120 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0607 05:11:54.125844 139665927477120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0607 05:11:54.228761 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0607 05:11:54.228985 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0607 05:11:54.229093 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0607 05:11:54.232770 139665927477120 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0607 05:11:54.254992 139665927477120 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0607 05:11:54.255142 139665927477120 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0607 05:11:54.456901 139665927477120 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0607 05:11:54.457129 139665927477120 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0607 05:11:54.825880 139665927477120 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0607 05:11:54.826107 139665927477120 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0607 05:11:55.236722 139665927477120 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0607 05:11:55.237162 139665927477120 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0607 05:11:55.772656 139665927477120 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0607 05:11:55.772876 139665927477120 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0607 05:11:56.325133 139665927477120 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0607 05:11:56.325376 139665927477120 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0607 05:11:57.061223 139665927477120 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0607 05:11:57.061474 139665927477120 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0607 05:11:57.330132 139665927477120 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0607 05:11:57.379759 139665927477120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0607 05:11:57.485671 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0607 05:11:57.485856 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0607 05:11:57.485917 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0607 05:11:57.487864 139665927477120 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0607 05:11:57.518413 139665927477120 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0607 05:11:57.518591 139665927477120 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0607 05:11:57.730841 139665927477120 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0607 05:11:57.731034 139665927477120 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0607 05:11:58.236048 139665927477120 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0607 05:11:58.236277 139665927477120 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0607 05:11:58.686600 139665927477120 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0607 05:11:58.686837 139665927477120 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0607 05:11:59.871836 139665927477120 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0607 05:11:59.872068 139665927477120 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0607 05:12:00.463660 139665927477120 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0607 05:12:00.463898 139665927477120 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0607 05:12:01.160475 139665927477120 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0607 05:12:01.160696 139665927477120 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0607 05:12:01.492629 139665927477120 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0607 05:12:01.532434 139665927477120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0607 05:12:01.634317 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0607 05:12:01.634579 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0607 05:12:01.634681 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0607 05:12:01.637373 139665927477120 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0607 05:12:01.661499 139665927477120 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0607 05:12:01.661674 139665927477120 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0607 05:12:01.874756 139665927477120 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0607 05:12:01.874970 139665927477120 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0607 05:12:02.573416 139665927477120 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0607 05:12:02.573670 139665927477120 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0607 05:12:02.978940 139665927477120 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0607 05:12:02.979139 139665927477120 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0607 05:12:03.416729 139665927477120 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0607 05:12:03.416924 139665927477120 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0607 05:12:03.830726 139665927477120 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0607 05:12:03.830930 139665927477120 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0607 05:12:04.403460 139665927477120 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0607 05:12:04.403661 139665927477120 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0607 05:12:04.549082 139665927477120 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0607 05:12:04.575889 139665927477120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0607 05:12:04.650367 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0607 05:12:04.650547 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0607 05:12:04.650624 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0607 05:12:04.652177 139665927477120 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0607 05:12:04.666298 139665927477120 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0607 05:12:04.666407 139665927477120 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0607 05:12:04.838695 139665927477120 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0607 05:12:04.838864 139665927477120 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0607 05:12:05.208328 139665927477120 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0607 05:12:05.208525 139665927477120 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0607 05:12:05.592353 139665927477120 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0607 05:12:05.592559 139665927477120 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0607 05:12:06.351833 139665927477120 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0607 05:12:06.352016 139665927477120 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0607 05:12:06.862660 139665927477120 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0607 05:12:06.862845 139665927477120 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0607 05:12:07.500724 139665927477120 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0607 05:12:07.500899 139665927477120 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0607 05:12:07.703271 139665927477120 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0607 05:12:07.728648 139665927477120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0607 05:12:07.811191 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0607 05:12:07.811344 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0607 05:12:07.811413 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0607 05:12:07.812927 139665927477120 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0607 05:12:07.828541 139665927477120 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0607 05:12:07.828654 139665927477120 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0607 05:12:08.004588 139665927477120 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0607 05:12:08.004770 139665927477120 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0607 05:12:08.433904 139665927477120 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0607 05:12:08.434088 139665927477120 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0607 05:12:08.882148 139665927477120 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0607 05:12:08.882334 139665927477120 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0607 05:12:09.448196 139665927477120 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0607 05:12:09.448368 139665927477120 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0607 05:12:10.021064 139665927477120 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0607 05:12:10.021246 139665927477120 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0607 05:12:10.801995 139665927477120 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0607 05:12:10.802178 139665927477120 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0607 05:12:11.016360 139665927477120 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0607 05:12:11.269663 139665927477120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0607 05:12:11.363252 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0607 05:12:11.363414 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0607 05:12:11.363506 139665927477120 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0607 05:12:11.365000 139665927477120 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0607 05:12:11.379104 139665927477120 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0607 05:12:11.379226 139665927477120 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0607 05:12:11.596602 139665927477120 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0607 05:12:11.596764 139665927477120 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0607 05:12:12.088382 139665927477120 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0607 05:12:12.088573 139665927477120 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0607 05:12:12.578929 139665927477120 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0607 05:12:12.579113 139665927477120 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0607 05:12:13.313979 139665927477120 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0607 05:12:13.314167 139665927477120 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0607 05:12:14.023686 139665927477120 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0607 05:12:14.023899 139665927477120 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0607 05:12:15.198442 139665927477120 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0607 05:12:15.198651 139665927477120 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0607 05:12:15.506238 139665927477120 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0607 05:12:15.532845 139665927477120 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.28s\n",
            "I0607 05:12:15.644733 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.28s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0607 05:12:15.652540 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0607 05:12:15.654133 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0607 05:12:15.654642 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0607 05:12:15.656036 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0607 05:12:15.657306 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0607 05:12:15.657752 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0607 05:12:15.658687 139665927477120 test_util.py:2309] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 30.874s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u8Jg_ZppOkXf"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAb2HWeyRIJt",
        "outputId": "ce96c01f-3563-47f3-d27e-9d3a11f65610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-07 05:12:16--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.24.128, 2404:6800:4003:c11::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.24.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-06-07 05:12:16 (201 MB/s) - ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz saved [20515344/20515344]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUqq2eOHROR7"
      },
      "source": [
        "## Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RxUzvhpzRP20"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'Apple', 'id':1}, {'name':'BadApple', 'id':2}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "errgWYcBRTql"
      },
      "source": [
        "## TF Records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bcRYJQU0RVUY"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QpepzXbfRZBN"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQmRsONORcsm",
        "outputId": "23497aa6-d057-4ab9-f102-9ae2209ad2ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecord file: Kinder/Workspace/Annotations/train.record\n",
            "Successfully created the TFRecord file: Kinder/Workspace/Annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J_xzym6R2Td"
      },
      "source": [
        "## Copy Model Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8Wp4pou7R38c"
      },
      "outputs": [],
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JqWZ9OTSWK2"
      },
      "source": [
        "## Update Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PamQt3F-STJt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8g0MgNNKSbK0"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZbtrioMLSboc"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "XJTil0XWSfj1"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KgJuKP5TShFl"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odssx2dEShmz"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0DYHqKznSjFk"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "l1yhpPvsSlFc"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=3000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoS3iq5KSm_M",
        "outputId": "84a3c6e2-1f32-4383-8aae-e0303334f5ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Kinder/Models/research/object_detection/model_main_tf2.py --model_dir=Kinder/Workspace/Models/SSD_MOBNET --pipeline_config_path=Kinder/Workspace/Models/SSD_MOBNET/pipeline.config --num_train_steps=3000\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfpnUwouT-fz",
        "outputId": "b75ac147-01ae-4b09-ce81-8b3f49b8a7fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opencv-contrib-python         4.1.2.30\n",
            "opencv-python                 4.1.2.30\n",
            "opencv-python-headless        4.1.2.30\n"
          ]
        }
      ],
      "source": [
        "!pip list | grep opencv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DKZzwWdUExb",
        "outputId": "bed90e46-8cee-4a34-f033-60709d33cb0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.1.2.30\n",
            "Uninstalling opencv-python-headless-4.1.2.30:\n",
            "  Successfully uninstalled opencv-python-headless-4.1.2.30\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall opencv-python-headless -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGq9gBFUUN1T",
        "outputId": "b94050bc-52cb-4c43-e7d8-8fb2f6f484d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python-headless==4.1.2.30\n",
            "  Using cached opencv_python_headless-4.1.2.30-cp37-cp37m-manylinux1_x86_64.whl (21.8 MB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.1.2.30) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-models-official 2.9.2 requires tensorflow~=2.9.0, but you have tensorflow 2.7.0+zzzcolab20220506150900 which is incompatible.\u001b[0m\n",
            "Successfully installed opencv-python-headless-4.1.2.30\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless==4.1.2.30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUfI3bM-UlJJ",
        "outputId": "d41d3637-5de2-4137-cea7-cf3d374762d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow                    2.7.0+zzzcolab20220506150900\n",
            "tensorflow-addons             0.17.0\n",
            "tensorflow-datasets           4.0.1\n",
            "tensorflow-estimator          2.7.0\n",
            "tensorflow-gcs-config         2.8.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io                 0.26.0\n",
            "tensorflow-io-gcs-filesystem  0.26.0\n",
            "tensorflow-metadata           1.8.0\n",
            "tensorflow-model-optimization 0.7.2\n",
            "tensorflow-probability        0.16.0\n",
            "tensorflow-text               2.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip list | grep tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "55XkzpyXUoJT"
      },
      "outputs": [],
      "source": [
        "#JANGAN LUPA INSTALL TF 2.7.0\n",
        "# !pip install tensorflow==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OGA-8gtTiQ0",
        "outputId": "f42bdb85-df9e-4b25-fa31-330cc18ce4ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-07 05:12:42.855808: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0607 05:12:42.859241 139865115998080 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 3000\n",
            "I0607 05:12:42.863367 139865115998080 config_util.py:552] Maybe overwriting train_steps: 3000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0607 05:12:42.863547 139865115998080 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0607 05:12:43.011645 139865115998080 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Kinder/Workspace/Annotations/train.record']\n",
            "I0607 05:12:43.015590 139865115998080 dataset_builder.py:162] Reading unweighted datasets: ['Kinder/Workspace/Annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Kinder/Workspace/Annotations/train.record']\n",
            "I0607 05:12:43.015820 139865115998080 dataset_builder.py:79] Reading record datasets for input file: ['Kinder/Workspace/Annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0607 05:12:43.015903 139865115998080 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0607 05:12:43.015973 139865115998080 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0607 05:12:43.018406 139865115998080 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0607 05:12:43.039032 139865115998080 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0607 05:12:52.561740 139865115998080 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0607 05:12:59.516783 139865115998080 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0607 05:13:01.114266 139865115998080 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "W0607 05:13:26.101249 139865115998080 util.py:182] Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "W0607 05:13:26.101479 139865115998080 util.py:182] Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "W0607 05:13:26.101566 139865115998080 util.py:182] Unresolved object in checkpoint: (root).optimizer.momentum\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "W0607 05:13:26.101722 139865115998080 util.py:190] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB2CZussYstJ"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YJjasB56YuO5"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARgInfedYvwq",
        "outputId": "16c2a81a-229d-4986-9884-ada8160786b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Kinder/Models/research/object_detection/model_main_tf2.py --model_dir=Kinder/Workspace/Models/SSD_MOBNET --pipeline_config_path=Kinder/Workspace/Models/SSD_MOBNET/pipeline.config --checkpoint_dir=Kinder/Workspace/Models/SSD_MOBNET\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyd-KTMRY2Xo",
        "outputId": "260d95db-7d1c-446b-fef1-0fc423d78473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0607 05:13:30.642169 140389242017664 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0607 05:13:30.642400 140389242017664 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0607 05:13:30.642511 140389242017664 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0607 05:13:30.642602 140389242017664 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0607 05:13:30.642721 140389242017664 model_lib_v2.py:1110] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2022-06-07 05:13:31.356612: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Kinder/Workspace/Annotations/test.record']\n",
            "I0607 05:13:31.510991 140389242017664 dataset_builder.py:162] Reading unweighted datasets: ['Kinder/Workspace/Annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Kinder/Workspace/Annotations/test.record']\n",
            "I0607 05:13:31.511218 140389242017664 dataset_builder.py:79] Reading record datasets for input file: ['Kinder/Workspace/Annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0607 05:13:31.511309 140389242017664 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0607 05:13:31.511377 140389242017664 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0607 05:13:31.513255 140389242017664 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0607 05:13:31.531448 140389242017664 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0607 05:13:35.386557 140389242017664 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0607 05:13:36.468942 140389242017664 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at Kinder/Workspace/Models/SSD_MOBNET\n",
            "I0607 05:13:39.795491 140389242017664 checkpoint_utils.py:140] Waiting for new checkpoint at Kinder/Workspace/Models/SSD_MOBNET\n",
            "INFO:tensorflow:Found new checkpoint at Kinder/Workspace/Models/SSD_MOBNET/ckpt-4\n",
            "I0607 05:13:39.796855 140389242017664 checkpoint_utils.py:149] Found new checkpoint at Kinder/Workspace/Models/SSD_MOBNET/ckpt-4\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "Traceback (most recent call last):\n",
            "  File \"Kinder/Models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"Kinder/Models/research/object_detection/model_main_tf2.py\", line 89, in main\n",
            "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1164, in eval_continuously\n",
            "    global_step=global_step,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 940, in eager_eval_loop\n",
            "    compute_eval_dict, args=(features, labels))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1316, in run\n",
            "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 2892, in call_for_each_replica\n",
            "    return self._call_for_each_replica(fn, args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 3695, in _call_for_each_replica\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 910, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 958, in _call\n",
            "    self._initialize(args, kwds, add_initializers_to=initializers)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 781, in _initialize\n",
            "    *args, **kwds))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3157, in _get_concrete_function_internal_garbage_collected\n",
            "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3557, in _maybe_define_function\n",
            "    graph_function = self._create_graph_function(args, kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3402, in _create_graph_function\n",
            "    capture_by_value=self._capture_by_value),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1143, in func_graph_from_py_func\n",
            "    func_outputs = python_func(*func_args, **func_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 672, in wrapped_fn\n",
            "    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\", line 1125, in autograph_handler\n",
            "    user_requested=True,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 445, in converted_call\n",
            "    result = converted_f(*effective_args, **kwargs)\n",
            "  File \"/tmp/__autograph_generated_filexfxen3r1.py\", line 20, in tf__compute_eval_dict\n",
            "    (losses_dict, prediction_dict) = ag__.converted_call(ag__.ld(_compute_losses_and_predictions_dicts), (ag__.ld(detection_model), ag__.ld(features), ag__.ld(labels)), dict(training_step=None, add_regularization_loss=ag__.ld(add_regularization_loss)), fscope)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 433, in converted_call\n",
            "    converted_f = _convert_actual(target_entity, program_ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 275, in _convert_actual\n",
            "    transformed, module, source_map = _TRANSPILER.transform(entity, program_ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 286, in transform\n",
            "    return self.transform_function(obj, user_context)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 491, in transform_function\n",
            "    nodes, ctx.namer, future_features=ctx.info.future_features)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/transpiler.py\", line 184, in create\n",
            "    nodes, include_source_map=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/loader.py\", line 102, in load_ast\n",
            "    source_map = origin_info.create_source_map(nodes, source, module.__file__)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 106, in create_source_map\n",
            "    resolve(node, code, filepath, node.lineno, node.col_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 275, in resolve\n",
            "    visitor.visit(node)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 227, in visit\n",
            "    self.generic_visit(node)\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 279, in generic_visit\n",
            "    self.visit(item)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 227, in visit\n",
            "    self.generic_visit(node)\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 279, in generic_visit\n",
            "    self.visit(item)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 227, in visit\n",
            "    self.generic_visit(node)\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 279, in generic_visit\n",
            "    self.visit(item)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 227, in visit\n",
            "    self.generic_visit(node)\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 279, in generic_visit\n",
            "    self.visit(item)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 227, in visit\n",
            "    self.generic_visit(node)\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 279, in generic_visit\n",
            "    self.visit(item)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 227, in visit\n",
            "    self.generic_visit(node)\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 279, in generic_visit\n",
            "    self.visit(item)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 227, in visit\n",
            "    self.generic_visit(node)\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 281, in generic_visit\n",
            "    self.visit(value)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 227, in visit\n",
            "    self.generic_visit(node)\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 279, in generic_visit\n",
            "    self.visit(item)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 227, in visit\n",
            "    self.generic_visit(node)\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 281, in generic_visit\n",
            "    self.visit(value)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 227, in visit\n",
            "    self.generic_visit(node)\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 279, in generic_visit\n",
            "    self.visit(item)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 227, in visit\n",
            "    self.generic_visit(node)\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 281, in generic_visit\n",
            "    self.visit(value)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/pyct/origin_info.py\", line 227, in visit\n",
            "    self.generic_visit(node)\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 275, in generic_visit\n",
            "    for field, value in iter_fields(node):\n",
            "  File \"/usr/lib/python3.7/ast.py\", line 186, in iter_fields\n",
            "    for field in node._fields:\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76vN8J12ZNsx"
      },
      "source": [
        "## Load Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "y17YJqMSam8Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "vcCbHTWdaqPw"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpJxcE57bE03"
      },
      "source": [
        "## Detect Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "mWkRiW-ibGoJ"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "KizmHGIqbKKv"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Ato6XL2LbMP_"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH_TEMP = os.path.join(paths['IMAGE_PATH'], 'test', 'rotated_by_15_Screen Shot 2018-06-07 at 2.57.42 PM.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "afmWPPJocujm"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "DtyTCL7_bkZw",
        "outputId": "bf122212-bb28-4b2d-f005-9afe6cf98011"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-87c51df316e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnum_detections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_detections'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ],
      "source": [
        "img = cv2.imread(IMAGE_PATH_TEMP)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAnbMM_6c-mv"
      },
      "source": [
        "## Freezing Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "rfiSECt3dAZg"
      },
      "outputs": [],
      "source": [
        "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "jOor8x-UdFI_"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idsH93WxdGlW",
        "outputId": "9522a239-8fe5-4e23-b1f9-b5d46e7979c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Kinder/Models/research/object_detection/exporter_main_v2.py  --input_type=image_tensor --pipeline_config_path=Kinder/Workspace/Models/SSD_MOBNET/pipeline.config --trained_checkpoint_dir=Kinder/Workspace/Models/SSD_MOBNET --output_directory=Kinder/Workspace/Models/SSD_MOBNET/Export\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCnDxHmQdJxV",
        "outputId": "9b9d190f-4791-4a1d-ab24-239d4794d0c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-07 05:16:04.057100: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0607 05:16:04.667840 140338686146432 deprecation.py:619] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa21a453310>, because it is not built.\n",
            "W0607 05:16:19.990558 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa21a453310>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa21a3517d0>, because it is not built.\n",
            "W0607 05:16:20.123476 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa21a3517d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205f62a90>, because it is not built.\n",
            "W0607 05:16:20.123703 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205f62a90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205842d90>, because it is not built.\n",
            "W0607 05:16:20.123814 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205842d90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa2059ec450>, because it is not built.\n",
            "W0607 05:16:20.123904 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa2059ec450>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2057e4890>, because it is not built.\n",
            "W0607 05:16:20.123994 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2057e4890>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205f41990>, because it is not built.\n",
            "W0607 05:16:20.124077 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205f41990>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa205be0f10>, because it is not built.\n",
            "W0607 05:16:20.124156 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa205be0f10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205b16610>, because it is not built.\n",
            "W0607 05:16:20.124234 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205b16610>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205b16a90>, because it is not built.\n",
            "W0607 05:16:20.124311 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205b16a90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa205b16210>, because it is not built.\n",
            "W0607 05:16:20.124393 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7fa205b16210>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205b16490>, because it is not built.\n",
            "W0607 05:16:20.124485 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205b16490>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2058e33d0>, because it is not built.\n",
            "W0607 05:16:20.124571 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2058e33d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa21a2d7510>, because it is not built.\n",
            "W0607 05:16:20.124650 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa21a2d7510>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa20583ee90>, because it is not built.\n",
            "W0607 05:16:20.124734 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa20583ee90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205a31750>, because it is not built.\n",
            "W0607 05:16:20.124810 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205a31750>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa20583e3d0>, because it is not built.\n",
            "W0607 05:16:20.124890 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa20583e3d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2059d6b50>, because it is not built.\n",
            "W0607 05:16:20.124967 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2059d6b50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205fe9250>, because it is not built.\n",
            "W0607 05:16:20.125045 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205fe9250>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205b16650>, because it is not built.\n",
            "W0607 05:16:20.125121 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205b16650>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2059a0550>, because it is not built.\n",
            "W0607 05:16:20.125198 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2059a0550>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa21a2d7550>, because it is not built.\n",
            "W0607 05:16:20.125284 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa21a2d7550>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2057f2b50>, because it is not built.\n",
            "W0607 05:16:20.125372 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2057f2b50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205bd92d0>, because it is not built.\n",
            "W0607 05:16:20.125450 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205bd92d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205f6e350>, because it is not built.\n",
            "W0607 05:16:20.125558 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205f6e350>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2057f2dd0>, because it is not built.\n",
            "W0607 05:16:20.125636 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2057f2dd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2059ba850>, because it is not built.\n",
            "W0607 05:16:20.125714 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2059ba850>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2057cab10>, because it is not built.\n",
            "W0607 05:16:20.125792 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2057cab10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2057ca3d0>, because it is not built.\n",
            "W0607 05:16:20.125868 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2057ca3d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2059e2810>, because it is not built.\n",
            "W0607 05:16:20.125944 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2059e2810>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205995dd0>, because it is not built.\n",
            "W0607 05:16:20.126019 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205995dd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205b81850>, because it is not built.\n",
            "W0607 05:16:20.126094 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205b81850>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2057a58d0>, because it is not built.\n",
            "W0607 05:16:20.126169 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2057a58d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2057a56d0>, because it is not built.\n",
            "W0607 05:16:20.126251 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2057a56d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2057a5890>, because it is not built.\n",
            "W0607 05:16:20.126326 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa2057a5890>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2057a5250>, because it is not built.\n",
            "W0607 05:16:20.126402 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2057a5250>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa20570e410>, because it is not built.\n",
            "W0607 05:16:20.126493 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa20570e410>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa21a2d7590>, because it is not built.\n",
            "W0607 05:16:20.126579 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa21a2d7590>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205736790>, because it is not built.\n",
            "W0607 05:16:20.126657 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205736790>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205736990>, because it is not built.\n",
            "W0607 05:16:20.126733 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205736990>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205736390>, because it is not built.\n",
            "W0607 05:16:20.126808 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205736390>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2057368d0>, because it is not built.\n",
            "W0607 05:16:20.126888 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa2057368d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205736ed0>, because it is not built.\n",
            "W0607 05:16:20.126965 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa205736ed0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205736f50>, because it is not built.\n",
            "W0607 05:16:20.127041 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa205736f50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa20571f990>, because it is not built.\n",
            "W0607 05:16:20.156686 140338686146432 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7fa20571f990>, because it is not built.\n",
            "2022-06-07 05:16:29.426011: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "W0607 05:16:45.065689 140338686146432 save.py:268] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: Kinder/Workspace/Models/SSD_MOBNET/Export/saved_model/assets\n",
            "I0607 05:16:50.423804 140338686146432 builder_impl.py:784] Assets written to: Kinder/Workspace/Models/SSD_MOBNET/Export/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to Kinder/Workspace/Models/SSD_MOBNET/Export/pipeline.config\n",
            "I0607 05:16:51.051850 140338686146432 config_util.py:254] Writing pipeline config file to Kinder/Workspace/Models/SSD_MOBNET/Export/pipeline.config\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ8A0MLHdahW"
      },
      "source": [
        "## Export to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "O8fb7OHtdcll"
      },
      "outputs": [],
      "source": [
        "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "sxrw5GKAdh3v"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xuzo0_VqdjVV",
        "outputId": "4f1c7f7d-131c-4d00-83f4-3e18f27afae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Kinder/Models/research/object_detection/export_tflite_graph_tf2.py  --pipeline_config_path=Kinder/Workspace/Models/SSD_MOBNET/pipeline.config --trained_checkpoint_dir=Kinder/Workspace/Models/SSD_MOBNET --output_directory=Kinder/Workspace/Models/SSD_MOBNET/tfliteexport\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bytFBDgidluN",
        "outputId": "b2685a4f-5d05-4e3d-ad75-4bf8909ea0f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-07 05:17:49.018703: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f71b050cf90>, because it is not built.\n",
            "W0607 05:17:57.765377 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f71b050cf90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f71b03d6690>, because it is not built.\n",
            "W0607 05:17:57.898082 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f71b03d6690>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71460ecf90>, because it is not built.\n",
            "W0607 05:17:57.898310 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71460ecf90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71461d2890>, because it is not built.\n",
            "W0607 05:17:57.898427 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71461d2890>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f714613bfd0>, because it is not built.\n",
            "W0607 05:17:57.898530 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f714613bfd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71460ec310>, because it is not built.\n",
            "W0607 05:17:57.898617 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71460ec310>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71b0323890>, because it is not built.\n",
            "W0607 05:17:57.898705 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71b0323890>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f714613be50>, because it is not built.\n",
            "W0607 05:17:57.898782 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f714613be50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71460969d0>, because it is not built.\n",
            "W0607 05:17:57.898857 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71460969d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f714609c350>, because it is not built.\n",
            "W0607 05:17:57.898932 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f714609c350>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f714667e210>, because it is not built.\n",
            "W0607 05:17:57.899016 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.convolutional.SeparableConv2D object at 0x7f714667e210>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7146395290>, because it is not built.\n",
            "W0607 05:17:57.899092 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7146395290>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f714609cf50>, because it is not built.\n",
            "W0607 05:17:57.899171 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f714609cf50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71b03d9350>, because it is not built.\n",
            "W0607 05:17:57.899245 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71b03d9350>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71463957d0>, because it is not built.\n",
            "W0607 05:17:57.899320 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71463957d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7146433350>, because it is not built.\n",
            "W0607 05:17:57.899394 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7146433350>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132fca450>, because it is not built.\n",
            "W0607 05:17:57.899477 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132fca450>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7146746c50>, because it is not built.\n",
            "W0607 05:17:57.899557 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7146746c50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132fbf3d0>, because it is not built.\n",
            "W0607 05:17:57.899639 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132fbf3d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7132fbf150>, because it is not built.\n",
            "W0607 05:17:57.899713 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7132fbf150>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71b0181f50>, because it is not built.\n",
            "W0607 05:17:57.899788 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71b0181f50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71b03d9390>, because it is not built.\n",
            "W0607 05:17:57.899862 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71b03d9390>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71466b6510>, because it is not built.\n",
            "W0607 05:17:57.899941 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71466b6510>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71b0034690>, because it is not built.\n",
            "W0607 05:17:57.900021 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71b0034690>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71460d1c10>, because it is not built.\n",
            "W0607 05:17:57.900101 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71460d1c10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71460d1bd0>, because it is not built.\n",
            "W0607 05:17:57.900175 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71460d1bd0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71465acc90>, because it is not built.\n",
            "W0607 05:17:57.900249 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71465acc90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71b0030b10>, because it is not built.\n",
            "W0607 05:17:57.900323 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71b0030b10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f714613b690>, because it is not built.\n",
            "W0607 05:17:57.900398 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f714613b690>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7132fa2f90>, because it is not built.\n",
            "W0607 05:17:57.900479 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7132fa2f90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7146292290>, because it is not built.\n",
            "W0607 05:17:57.900555 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7146292290>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7146292b50>, because it is not built.\n",
            "W0607 05:17:57.900634 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7146292b50>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132fb21d0>, because it is not built.\n",
            "W0607 05:17:57.900708 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132fb21d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71463edf90>, because it is not built.\n",
            "W0607 05:17:57.900782 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71463edf90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132fb2610>, because it is not built.\n",
            "W0607 05:17:57.900866 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132fb2610>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7132fb2790>, because it is not built.\n",
            "W0607 05:17:57.900947 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7132fb2790>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7146097b10>, because it is not built.\n",
            "W0607 05:17:57.901030 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7146097b10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71b03d93d0>, because it is not built.\n",
            "W0607 05:17:57.901105 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f71b03d93d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132f5e210>, because it is not built.\n",
            "W0607 05:17:57.901178 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132f5e210>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7132f5e0d0>, because it is not built.\n",
            "W0607 05:17:57.901252 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7132f5e0d0>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132f5e910>, because it is not built.\n",
            "W0607 05:17:57.901330 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132f5e910>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7132f5ec10>, because it is not built.\n",
            "W0607 05:17:57.901403 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f7132f5ec10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71b003ce90>, because it is not built.\n",
            "W0607 05:17:57.901493 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f71b003ce90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f714615fd90>, because it is not built.\n",
            "W0607 05:17:57.901570 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7f714615fd90>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132f47b10>, because it is not built.\n",
            "W0607 05:17:57.929540 140128996611968 save_impl.py:72] Skipping full serialization of Keras layer <keras.layers.core.lambda_layer.Lambda object at 0x7f7132f47b10>, because it is not built.\n",
            "2022-06-07 05:18:07.201675: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "W0607 05:18:21.756137 140128996611968 save.py:268] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 260). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: Kinder/Workspace/Models/SSD_MOBNET/tfliteexport/saved_model/assets\n",
            "I0607 05:18:26.905154 140128996611968 builder_impl.py:784] Assets written to: Kinder/Workspace/Models/SSD_MOBNET/tfliteexport/saved_model/assets\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ppUoAsNd43-"
      },
      "outputs": [],
      "source": [
        "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
        "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWPZFqFGd6nm"
      },
      "outputs": [],
      "source": [
        "command = \"tflite_convert \\\n",
        "--saved_model_dir={} \\\n",
        "--output_file={} \\\n",
        "--input_shapes=1,224,224,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WHMSAmfd8M2"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01gcXBFZd-Y-"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0nk-7u6eZaF"
      },
      "outputs": [],
      "source": [
        "!sudo cp -r /content/Kinder/Workspace/Models/SSD_MOBNET/tfliteexport /content/drive/My\\ Drive/Kinder-Metadata "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFn92qncfGim"
      },
      "outputs": [],
      "source": [
        "!sudo cp /content/drive/MyDrive/Kinder-Metadata/saved_model/detect_metadata.tflite /content/Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfYWLo2rZW3m"
      },
      "outputs": [],
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RX5mFi5ZjU2"
      },
      "outputs": [],
      "source": [
        "!sudo cp models.tar.gz /content/drive/My\\ Drive/Kinder-New"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOYRMaNobbxO"
      },
      "source": [
        "## TFLite Metadata Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyLNYQJ4bdbu"
      },
      "outputs": [],
      "source": [
        "!pip install -q tflite_support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKHziYrwcH2O"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install libportaudio2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtPIvwajb6VG"
      },
      "outputs": [],
      "source": [
        "from tflite_support.metadata_writers import object_detector\n",
        "from tflite_support.metadata_writers import writer_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnwqWfAade02"
      },
      "outputs": [],
      "source": [
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/ssd_mobilenet_v1.tflite -o ssd_mobilenet_v1.tflite\n",
        "!curl -L https://github.com/tensorflow/tflite-support/raw/master/tensorflow_lite_support/metadata/python/tests/testdata/object_detector/labelmap.txt -o ssd_mobilenet_labels.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCtnmrzaeKuO"
      },
      "outputs": [],
      "source": [
        "!echo \"Apple\" >> /content/Kinder/Workspace/Models/SSD_MOBNET/tfliteexport/saved_model/labels.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCn2UUd5eXbO"
      },
      "outputs": [],
      "source": [
        "!echo \"BadApple\" >> /content/Kinder/Workspace/Models/SSD_MOBNET/tfliteexport/saved_model/labels.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp48Q-DXearV"
      },
      "outputs": [],
      "source": [
        "!cat /content/Kinder/Workspace/Models/SSD_MOBNET/tfliteexport/saved_model/labels.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdHF31hxd1rD"
      },
      "outputs": [],
      "source": [
        "ObjectDetectorWriter = object_detector.MetadataWriter\n",
        "_MODEL_PATH = \"/content/Kinder/Workspace/Models/SSD_MOBNET/tfliteexport/saved_model/detect.tflite\"\n",
        "# Task Library expects label files that are in the same format as the one below.\n",
        "_LABEL_FILE = \"/content/Kinder/Workspace/Models/SSD_MOBNET/tfliteexport/saved_model/labels.txt\"\n",
        "_SAVE_TO_PATH = \"/content/Kinder/Workspace/Models/SSD_MOBNET/tfliteexport/saved_model/detect_metadata.tflite\"\n",
        "# Normalization parameters is required when reprocessing the image. It is\n",
        "# optional if the image pixel values are in range of [0, 255] and the input\n",
        "# tensor is quantized to uint8. See the introduction for normalization and\n",
        "# quantization parameters below for more details.\n",
        "# https://www.tensorflow.org/lite/models/convert/metadata#normalization_and_quantization_parameters)\n",
        "_INPUT_NORM_MEAN = 127.5\n",
        "_INPUT_NORM_STD = 127.5\n",
        "\n",
        "# Create the metadata writer.\n",
        "writer = ObjectDetectorWriter.create_for_inference(\n",
        "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
        "    [_LABEL_FILE])\n",
        "\n",
        "# Verify the metadata generated by metadata writer.\n",
        "print(writer.get_metadata_json())\n",
        "\n",
        "# Populate the metadata into the model.\n",
        "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9QLcUepe-_m"
      },
      "outputs": [],
      "source": [
        "from tflite_support import metadata\n",
        "\n",
        "displayer = metadata.MetadataDisplayer.with_model_file(\"/lite-model_object_detection_mobile_object_labeler_v1_1.tflite\")\n",
        "print(\"Metadata populated:\")\n",
        "print(displayer.get_metadata_json())\n",
        "print(\"=============================\")\n",
        "print(\"Associated file(s) populated:\")\n",
        "print(displayer.get_packed_associated_file_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCe-cJrJhSZ3"
      },
      "outputs": [],
      "source": [
        "!wget https://tfhub.dev/google/lite-model/object_detection/mobile_object_labeler_v1/1?lite-format=tflite"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Object-Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}